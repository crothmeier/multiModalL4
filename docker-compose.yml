version: "3.9"

x-vllm-base: &vllm-base
  runtime: nvidia
  environment:
    NVIDIA_VISIBLE_DEVICES: all
    NVIDIA_DRIVER_CAPABILITIES: compute,utility
    HF_TOKEN: ${HF_TOKEN:-}
  volumes:
    - /mnt/models:/models:ro
  deploy:
    resources:
      reservations:
        devices:
          - capabilities: [gpu]
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  cap_add:
    - NET_BIND_SERVICE

services:
  general-llm:
    <<: *vllm-base
    build: ./services/vllm-general
    image: multimodal-stack/vllm-general:latest
    command:
      - --model=/models/mistral-awq
      - --tokenizer=mistralai/Mistral-7B-Instruct-v0.2
      - --trust-remote-code
      - --download-dir=/models
      - --max-model-len=8192
      - --gpu-memory-utilization=0.50
      - --host=0.0.0.0
      - --port=8000

  code-llm:
    <<: *vllm-base
    build: ./services/vllm-code
    image: multimodal-stack/vllm-code:latest
    command:
      - --model=/models/deepseek-gptq
      - --tokenizer=deepseek-ai/deepseek-coder-6.7b-instruct
      - --trust-remote-code
      - --download-dir=/models
      - --max-model-len=8192
      - --gpu-memory-utilization=0.35
      - --host=0.0.0.0
      - --port=8000

  vl-llm:
    <<: *vllm-base
    build: ./services/vllm-vl
    image: multimodal-stack/vllm-vl:latest
    command:
      - --model=/models/deepseek-vl-1.3b-chat
      - --trust-remote-code
      - --download-dir=/models
      - --gpu-memory-utilization=0.25
      - --host=0.0.0.0
      - --port=8000

  api:
    build: ./services/api-gateway
    image: multimodal-stack/api-gateway:latest
    ports:
      - "8080:8080"
    environment:
      ROUTES: |
        /chat/completions -> general-llm:8000/v1
        /code/completions -> code-llm:8000/v1
        /vision/completions -> vl-llm:8000/v1
    depends_on:
      - general-llm
      - code-llm
      - vl-llm
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 3s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE

  # Whisper & Piper remain in 'full' profile - see README for usage
  whisper:
    image: ghcr.io/ggerganov/whisper.cpp:v1.6.1-cuda12
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    volumes:
      - /tmp/audio:/audio:ro
    profiles:
      - full

  piper:
    image: rhasspy/piper:1.2.0
    volumes:
      - ./models/piper:/home/piper/.local/share/piper/voices:ro
    profiles:
      - full

  # Prometheus disabled until config exists (Phase 2)
  # prometheus:
  #   image: prom/prometheus:v2.52.0
  #   volumes:
  #     - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #   ports:
  #     - "9090:9090"
  #   profiles:
  #     - monitoring

  dcgm:
    image: nvcr.io/nvidia/k8s/dcgm-exporter:3.3.5-3.4.1-ubuntu22.04
    runtime: nvidia
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    ports:
      - "9400:9400"
    profiles:
      - monitoring
